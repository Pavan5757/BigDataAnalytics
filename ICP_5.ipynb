{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nSc3IOaQNQu2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef1d63e7-45df-4147-e8d0-8d133ab22365"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found: {'classifier__C': 0.1, 'classifier__kernel': 'linear', 'pca__n_components': 3}\n",
            "Best cross-validation score: 0.96\n",
            "Test set score: 1.00\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# 1. Load dataset\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 2. Create pipeline\n",
        "pipe = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('pca', PCA()),\n",
        "    ('classifier', SVC())\n",
        "])\n",
        "\n",
        "# 3. Define parameter grid\n",
        "param_grid = {\n",
        "    'pca__n_components': [2, 3],\n",
        "    'classifier__C': [0.1, 1, 10],\n",
        "    'classifier__kernel': ['linear', 'rbf']\n",
        "}\n",
        "\n",
        "# 4. GridSearchCV\n",
        "grid = GridSearchCV(pipe, param_grid)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# 5. Results\n",
        "print(\"Best parameters found:\", grid.best_params_)\n",
        "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
        "print(\"Test set score: {:.2f}\".format(grid.score(X_test, y_test)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for 3 fold, 5 fold and 7 fold cross validation\n",
        "\n",
        "Replace classifier, SVC with RandomForestClassifier and LogisticRegression, Perceptron, knn .\n",
        "\n",
        "Update the param_grid accordingly (e.g., for RandomForestClassifier, use n_estimators, max_depth, etc.)\n",
        "\n",
        "Also replace Gridsearch with randomnsearch function.\n",
        "\n",
        "Relplace with with your own csv dataset using code below:"
      ],
      "metadata": {
        "id": "tqJp7J-jNbu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression, Perceptron\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from scipy.stats import randint\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "data = pd.read_csv(\"/content/college_student_placement_dataset.csv\")\n",
        "X = data.drop([\"Internship_Experience\", 'College_ID', 'CGPA', 'Projects_Completed'], axis=1)\n",
        "y = data[\"Placement\"]"
      ],
      "metadata": {
        "id": "aUipqQf8Pcao"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the data\n",
        "\n",
        "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "numeric_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', numeric_pipeline, numerical_cols),\n",
        "    ('cat', categorical_pipeline, categorical_cols)\n",
        "])\n"
      ],
      "metadata": {
        "id": "VGhFt8IT-out"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "models = {\n",
        "    \"RandomForest\": (RandomForestClassifier(), {\n",
        "        'classifier__n_estimators': randint(50, 200),\n",
        "        'classifier__max_depth': randint(3, 20)\n",
        "    }),\n",
        "    \"LogisticRegression\": (LogisticRegression(max_iter=1000), {\n",
        "        'classifier__C': [0.01, 0.1, 1, 10],\n",
        "        'classifier__penalty': ['l2']\n",
        "    }),\n",
        "    \"Perceptron\": (Perceptron(max_iter=1000), {\n",
        "        'classifier__penalty': ['l2', 'elasticnet'],\n",
        "        'classifier__alpha': [0.0001, 0.001, 0.01]\n",
        "    }),\n",
        "    \"KNN\": (KNeighborsClassifier(), {\n",
        "        'classifier__n_neighbors': [3, 5, 7, 9],\n",
        "        'classifier__weights': ['uniform', 'distance']\n",
        "    })\n",
        "}\n",
        "\n",
        "for cv_fold in [3, 5, 7]:\n",
        "    print(f\"\\n=== Cross-validation: {cv_fold}-fold ===\")\n",
        "    for name, (clf, param_dist) in models.items():\n",
        "        pipe = Pipeline([\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('pca', PCA()),\n",
        "            ('classifier', clf)\n",
        "        ])\n",
        "        search = RandomizedSearchCV(pipe, {\n",
        "            'pca__n_components': [2, 3, 5],\n",
        "            **param_dist\n",
        "        }, n_iter=10, cv=cv_fold, random_state=42)\n",
        "        search.fit(X_train, y_train)\n",
        "        print(f\"\\n{name} | Best Params: {search.best_params_}\")\n",
        "        print(f\"{name} | CV Score: {search.best_score_:.2f}\")\n",
        "        print(f\"{name} | Test Score: {search.score(X_test, y_test):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdJmDxtd-1Fh",
        "outputId": "287da72d-3b81-4949-c73b-ae8d50d1109a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Cross-validation: 3-fold ===\n",
            "\n",
            "RandomForest | Best Params: {'classifier__max_depth': 9, 'classifier__n_estimators': 171, 'pca__n_components': 5}\n",
            "RandomForest | CV Score: 0.94\n",
            "RandomForest | Test Score: 0.95\n",
            "\n",
            "LogisticRegression | Best Params: {'pca__n_components': 5, 'classifier__penalty': 'l2', 'classifier__C': 0.1}\n",
            "LogisticRegression | CV Score: 0.93\n",
            "LogisticRegression | Test Score: 0.93\n",
            "\n",
            "Perceptron | Best Params: {'pca__n_components': 3, 'classifier__penalty': 'l2', 'classifier__alpha': 0.01}\n",
            "Perceptron | CV Score: 0.91\n",
            "Perceptron | Test Score: 0.87\n",
            "\n",
            "KNN | Best Params: {'pca__n_components': 5, 'classifier__weights': 'uniform', 'classifier__n_neighbors': 5}\n",
            "KNN | CV Score: 0.94\n",
            "KNN | Test Score: 0.95\n",
            "\n",
            "=== Cross-validation: 5-fold ===\n",
            "\n",
            "RandomForest | Best Params: {'classifier__max_depth': 9, 'classifier__n_estimators': 142, 'pca__n_components': 5}\n",
            "RandomForest | CV Score: 0.94\n",
            "RandomForest | Test Score: 0.94\n",
            "\n",
            "LogisticRegression | Best Params: {'pca__n_components': 5, 'classifier__penalty': 'l2', 'classifier__C': 1}\n",
            "LogisticRegression | CV Score: 0.93\n",
            "LogisticRegression | Test Score: 0.93\n",
            "\n",
            "Perceptron | Best Params: {'pca__n_components': 5, 'classifier__penalty': 'elasticnet', 'classifier__alpha': 0.001}\n",
            "Perceptron | CV Score: 0.91\n",
            "Perceptron | Test Score: 0.89\n",
            "\n",
            "KNN | Best Params: {'pca__n_components': 5, 'classifier__weights': 'uniform', 'classifier__n_neighbors': 5}\n",
            "KNN | CV Score: 0.94\n",
            "KNN | Test Score: 0.95\n",
            "\n",
            "=== Cross-validation: 7-fold ===\n",
            "\n",
            "RandomForest | Best Params: {'classifier__max_depth': 9, 'classifier__n_estimators': 142, 'pca__n_components': 5}\n",
            "RandomForest | CV Score: 0.94\n",
            "RandomForest | Test Score: 0.94\n",
            "\n",
            "LogisticRegression | Best Params: {'pca__n_components': 5, 'classifier__penalty': 'l2', 'classifier__C': 10}\n",
            "LogisticRegression | CV Score: 0.93\n",
            "LogisticRegression | Test Score: 0.93\n",
            "\n",
            "Perceptron | Best Params: {'pca__n_components': 5, 'classifier__penalty': 'elasticnet', 'classifier__alpha': 0.0001}\n",
            "Perceptron | CV Score: 0.91\n",
            "Perceptron | Test Score: 0.92\n",
            "\n",
            "KNN | Best Params: {'pca__n_components': 5, 'classifier__weights': 'uniform', 'classifier__n_neighbors': 5}\n",
            "KNN | CV Score: 0.94\n",
            "KNN | Test Score: 0.95\n"
          ]
        }
      ]
    }
  ]
}